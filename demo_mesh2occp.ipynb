{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch3d\n",
    "from pytorch3d import _C\n",
    "from pytorch3d.io import load_obj, save_obj, load_objs_as_meshes\n",
    "from pytorch3d.structures import Meshes, Pointclouds\n",
    "from pytorch3d.ops import sample_points_from_meshes, knn_points, estimate_pointcloud_normals, knn_gather, cubify\n",
    "from pytorch3d.loss.point_mesh_distance import point_mesh_edge_distance, point_mesh_face_distance\n",
    "import trimesh\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyvista as pv\n",
    "pv.start_xvfb()\n",
    "pv.set_jupyter_backend('html')\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, DistributedSampler  \n",
    "from torch.nn.parallel import DistributedDataParallel as DDP  \n",
    "\n",
    "# # from pytorch3d.structures import Meshes\n",
    "\n",
    "# from .utils import one_hot_sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ops.mesh_geometry import *\n",
    "# import pymeshlab as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trimesh_tem = trimesh.load('./data_example/Bull.obj', force='mesh')\n",
    "\n",
    "# delete a few faces to make the mesh non-watertight\n",
    "# trimesh_tem.faces[590:593,:] = trimesh_tem.faces[590:591,:]\n",
    "print(trimesh_tem.is_watertight)\n",
    "\n",
    "device = torch.device(\"cuda:6\")\n",
    "\n",
    "mesh_tem = Meshes(verts=[torch.from_numpy(trimesh_tem.vertices).float()], \n",
    "                  faces=[torch.from_numpy(trimesh_tem.faces).long()]).to(device)\n",
    "\n",
    "mesh_tem = normalize_mesh(mesh_tem) # normalize the mesh to fit in the unit cube\n",
    "\n",
    "print(mesh_tem.verts_packed().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pv.Plotter(notebook=True)\n",
    "\n",
    "trimesh_tem = trimesh.Trimesh(vertices=mesh_tem.verts_list()[0].cpu().numpy(), faces=mesh_tem.faces_list()[0].cpu().numpy())\n",
    "\n",
    "pl.add_mesh(trimesh_tem, color='lightblue', show_edges=True, opacity=1)\n",
    "\n",
    "\n",
    "# pl.add_points(coordinates_downsampled.cpu().numpy()[np.random.choice(n_points, 1000)], color='red', point_size=5)\n",
    "\n",
    "# pl.camera.roll = 10\n",
    "pl.camera.elevation = 140\n",
    "pl.camera.azimuth = 60\n",
    "pl.camera.zoom = 1.3\n",
    "\n",
    "pl.show() #screenshot='out_exp/tem_mesh_2.png', window_size=[800,800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxelizer = Differentiable_Voxelizer(bbox_density=128)\n",
    "\n",
    "\n",
    "sample_size = 256\n",
    "\n",
    "meshbbox = mesh_tem.get_bounding_boxes()[0]\n",
    "\n",
    "coordinates_downsampled = torch.stack(torch.meshgrid(torch.linspace(meshbbox[0,0], meshbbox[0,1], sample_size),\n",
    "                                                        torch.linspace(meshbbox[1,0], meshbbox[1,1], sample_size),\n",
    "                                                        torch.linspace(meshbbox[2,0], meshbbox[2,1], sample_size)), dim=-1)\n",
    "\n",
    "coordinates_downsampled = coordinates_downsampled.view(-1, 3).to(device)\n",
    "\n",
    "n_points = coordinates_downsampled.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    #sdf_result = signed_distance_field(mesh_tem, coordinates_downsampled, allow_grad=False)\n",
    "    occp_result = occupancy(mesh_tem, coordinates_downsampled, allow_grad=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-GPUs Accelerating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arctan_occp = arctan_det_occp(mesh_tem)\n",
    "\n",
    "# # if u wanna use multi-gpus (but may not be faster)\n",
    "\n",
    "# output_gpu = torch.device(\"cuda:4\")\n",
    "\n",
    "# arctan_occp = nn.DataParallel(arctan_occp, device_ids=[4,5,6,7], output_device=output_gpu)\n",
    "# arctan_occp = arctan_occp.cuda()\n",
    "# arctan_occp = arctan_occp.half()\n",
    "\n",
    "\n",
    "# dats_set = torch.utils.data.TensorDataset(coordinates_downsampled.half().cpu(), torch.arange(0, n_points).long())\n",
    "\n",
    "# sampler = DistributedSampler(dats_set)  \n",
    "\n",
    "# dataloader = torch.utils.data.DataLoader(dats_set, batch_size=128**3, shuffle=False, drop_last=False, sampler=sampler)\n",
    "\n",
    "# arctan_occp.eval()\n",
    "\n",
    "# occp_result = torch.zeros(n_points, dtype=torch.half, device=output_gpu)\n",
    "\n",
    "# opp_result = occp_result.half()\n",
    "\n",
    "\n",
    "# for i, (data, idx) in enumerate(dataloader): ### multi-gpu\n",
    "#     points = data.cuda()\n",
    "#     indx = idx.to(output_gpu)\n",
    "#     with torch.no_grad():\n",
    "#         occp = arctan_occp.forward(points, 2000)\n",
    "#         occp_result[indx] = occp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, _ = _C.point_face_dist_forward(coordinates_downsampled.view(-1, 3).to(device),\n",
    "                        torch.tensor([0], device=device, dtype=torch.int64),\n",
    "                        mesh_tem.verts_packed()[mesh_tem.faces_packed(),:].to(device),\n",
    "                        torch.tensor([0], device=device, dtype=torch.int64),\n",
    "                        n_points, 1e-5)\n",
    "\n",
    "occpfield = occp_result.view(1, sample_size, sample_size, sample_size)\n",
    "occpfield = occpfield.permute(0, 3, 2, 1)\n",
    "\n",
    "sdf = dist*torch.where(occp_result>0.5, -1.0, 1.0)\n",
    "\n",
    "sdf_trg = sdf.view(1, sample_size, sample_size, sample_size)\n",
    "sdf_trg = sdf_trg.permute(0, 3, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-cubify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cubified = cubify(-sdf_trg, 1e-5) # cubify the voxel grid, which is the inverse operation of voxelization\n",
    "\n",
    "cubified = cubified.update_padded(cubified.verts_padded()*(meshbbox[:,1].view(1,1, 3).to(device)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pv.Plotter(notebook=True)\n",
    "trimesh_cubified = trimesh.Trimesh(cubified.verts_packed().detach().cpu().numpy(), cubified.faces_packed().detach().cpu().numpy())\n",
    "trimesh_cubified = trimesh.smoothing.filter_laplacian(trimesh_cubified, iterations=4)\n",
    "\n",
    "trimesh_original = trimesh.Trimesh(mesh_tem.verts_list()[0].cpu().numpy(), mesh_tem.faces_list()[0].cpu().numpy())\n",
    "\n",
    "# pl.add_mesh(trimesh_original, color='lightgreen', show_edges=True, opacity=0.2)\n",
    "\n",
    "pl.add_mesh(trimesh_cubified, color='lightgreen', opacity=1, show_edges=False)\n",
    "\n",
    "pl.camera.elevation = 140\n",
    "pl.camera.azimuth = 60\n",
    "pl.camera.zoom = 1.3\n",
    "\n",
    "pl.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometery3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
